
# Как это работает локально (по слоям)

## 1) Chrome + Built-in AI

* В Chrome (Early Preview) есть **встроенные ИИ-API**: Summarizer, Writer, Rewriter, Translator, Proofreader, Prompt (в т.ч. мультимодальность).
* Они вызываются из JS **напрямую в браузере**. Обработка идёт **на устройстве** (модель Gemini Nano загружается/кешируется самим Chrome при первом использовании).
* Никаких запросов на ваш сервер; доступ к сети не обязателен.

> Важно: первый запуск может занять чуть дольше — Chrome докачает и проинициализирует локальную модель. Потом всё мгновенно и офлайн.

## 2) Расширение (Manifest V3)

* **content script** на `youtube.com` вытаскивает транскрипт (или просит вставить .srt/.vtt), управляет плеером (переход по таймкодам).
* **side panel / popup** — UI (Summary, Timeline, Cards).
* **service worker** расширения — координация и вызовы AI-API.
* **IndexedDB** — локальное хранилище материалов (конспект, таймлайн, карточки).

Минимальные права в `manifest.json`:

```json
{
  "manifest_version": 3,
  "name": "YouTube→Учёба (Local AI)",
  "version": "0.1.0",
  "permissions": ["storage", "scripting", "sidePanel"],
  "host_permissions": ["https://www.youtube.com/*"],
  "action": { "default_title": "Summarize" },
  "background": { "service_worker": "sw.js" },
  "content_scripts": [{
    "matches": ["https://www.youtube.com/*"],
    "js": ["content.js"]
  }],
  "side_panel": { "default_path": "panel.html" }
}
```

## 3) Веб-приложение (PWA) офлайн

* Лёгкая PWA для **просмотра** сохранённых материалов **без интернета**.
* Статические файлы и шрифты **кешируются** сервис-воркером, данные — в **IndexedDB**.

# Поток данных (end-to-end)

1. **Получение текста**

   * Content script извлекает auto-captions YouTube (или пользователь загружает `.srt/.vtt` / вставляет текст).
   * Длинный текст **режется на чанки** (например, по таймкодам или по ~2–3 тыс. символов).

2. **Суммаризация (локально)**

   * Для каждого чанка вызываем **Summarizer API** → получаем пункты конспекта и метки разделов.
   * Объединяем в общий TL;DR и **Timeline** (start/end/title/краткое описание).

3. **Карточки (локально)**

   * Вызываем **Writer API** на основе конспекта → генерим 8–12 Q/A карточек (с привязкой к таймкодам).
   * Прогоняем результат через **Proofreader API** (правка грамматики).

4. **Упрощение текста (локально)**

   * По клику “Simplify” отправляем выделенный абзац в **Rewriter API** → получаем понятную версию.

5. **Сохранение и офлайн**

   * Всё складываем в IndexedDB: `{ videoId, summary, terms, timeline[], cards[] }`.
   * Кнопка «Save to PWA» делает экспорт/импорт или просто открывает PWA, которая читает те же данные.

6. **Офлайн-режим**

   * ИИ-вызовы продолжают работать (модель уже на устройстве), UI и данные доступны из кеша и IndexedDB.

# Псевдокод вызовов (чтобы понять механику)

> Ниже — **псевдокод**, имена методов могут отличаться от финального API; задача — показать принцип: всё из браузера, без fetch на сервер.

```ts
// Summarize (локально)
const summary = await chrome.ai.summarizer.run({
  text: chunkText,
  instruction: "Сделай структурированный конспект: bullets[5-10], terms[]. Верни JSON."
});

// Cards (локально)
const rawCards = await chrome.ai.writer.run({
  text: combinedSummary,
  instruction: "Сгенерируй 8-12 Q/A карточек. Формат [{front,back,ts}]"
});

// Proofread (локально)
const cleanCards = await chrome.ai.proofreader.run({
  text: JSON.stringify(rawCards),
  instruction: "Исправь грамматику, сохрани смысл и формат JSON."
});

// Simplify (локально)
const simpler = await chrome.ai.rewriter.run({
  text: selectedPassage,
  instruction: "Объясни проще для 15-летнего, ≤120 слов, без потери точности."
});
```

# Что с транскриптом, если нет сети?

* Если у видео **есть** встроенные субтитры — content script их читает **без облака**.
* Если **нет** — просим пользователя **вставить текст**/загрузить `.srt/.vtt`.
  (ASR «самому из аудио» мы в MVP **не делаем**, чтобы сохранить чисто локальную логику и уложиться в сроки.)

# Производительность и ограничения

* **Холодный старт**: первый вызов подгрузит модель (делает Chrome). Дальше — быстро.
* **Длинные видео**: чанкование + прогресс-бар, обработка по частям (UI остаётся отзывчивым).
* **Память**: храним только необходимое (bullets, таймлайн, карточки); исходный транскрипт можно чистить.
* **Приватность**: никаких отправок на сервер; разрешения в manifest — минимальные.

# Когда нужен гибрид (опционально)

* Если потребуется: синхронизация прогресса между устройствами или суммаризация **очень длинных** курсов — можно добавить **Firebase AI Logic/Gemini API** как *необязательный* fallback (по явной опции в настройках). По умолчанию — **чисто локально**.

---
